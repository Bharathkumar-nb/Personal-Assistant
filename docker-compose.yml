services:
  redis:
    image: "redis:alpine"
    ports:
      - "6379:6379"

  voice-to-text:
    build:
      context: .
      dockerfile: Dockerfile.voice-to-text
    volumes:
      - /mnt/d/Learning/Personal-Assistant:/app
      - /mnt/wslg:/mnt/wslg # Share PulseAudio configuration
    environment:
      - PULSE_SERVER=unix:/mnt/wslg/PulseServer
      - NVIDIA_VISIBLE_DEVICES=all
    network_mode: "host" # Use host network to enable audio communication
    runtime: nvidia
    depends_on:
      - redis
    #restart: on-failure
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost || exit 1"]
      interval: 1m30s
      timeout: 10s
      retries: 3

  text-processing:
    image: ai/meta-llama:3.1-8B-Instruct-cuda-12.6
    volumes:
      - /mnt/d/Learning/Personal-Assistant:/app
    runtime: nvidia
    depends_on:
      - redis
    ports:
      - "8000:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    env_file:
      - .env
    #restart: on-failure
    command: ["vllm", "serve", "--max-model-len", "512", "--dtype", "float16", "--block-size", "32", "--quantization", "fp8"]
    network_mode: "host"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost || exit 1"]
      interval: 1m30s
      timeout: 10s
      retries: 3

  text-to-speech:
    build:
      context: .
      dockerfile: Dockerfile.text-to-speech
    volumes:
      - /mnt/d/Learning/Personal-Assistant:/app
      - /mnt/wslg:/mnt/wslg
    runtime: nvidia
    depends_on:
      - redis
    environment:
      - PULSE_SERVER=unix:/mnt/wslg/PulseServer
      - NVIDIA_VISIBLE_DEVICES=all
    env_file:
      - .env
    network_mode: "host" # Use host network to enable audio communication
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost || exit 1"]
      interval: 1m30s
      timeout: 10s
      retries: 3

